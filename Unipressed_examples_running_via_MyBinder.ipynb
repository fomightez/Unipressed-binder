{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83dab5f7-175b-4112-8db6-828fbd270151",
   "metadata": {},
   "source": [
    "# Unipressed examples running via MyBinder\n",
    "\n",
    "There's a Python package, [Unipressed](https://multimeric.github.io/Unipressed/), by Michael Milton ([@multimeric](https://twitter.com/multimeric)) that allows programmatic access query UniProt's new REST API.  \n",
    "\n",
    "This notebook combines some of my examples on StackOverflow and Biostars to work in sessions served by MyBinder.\n",
    "This is designed so you can easily edit these and run your own versions to test things out or collect useful information.  \n",
    "Be aware though this MyBinder-served session has limited computational resources and so you may easily exceed what is possible here and need to take the ideas and code and move to where you have more resources. Additionally, MyBinder blocks FTP ports to prevent abuse and so not all routes work to retrieve data.\n",
    "\n",
    "If you do make something useful in your session, grab the code and save it on your local machine or save the current notebook and download it to your machine to upload it to later sessions to pick up where you left off. The same goes for any data you generate! (You'll need to run the installs at the top everytime unless I have set up the environment to already include them installed at session start-up. I HAVE NOT DONE THIS YET.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad985a-705c-400d-9244-0cdb2215571e",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "### Prepare environment in session by installing packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea802c9-904b-4c3e-aad9-62e281541c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unipressed\n",
      "  Downloading unipressed-1.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from unipressed) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.3.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from unipressed) (4.12.2)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Downloading numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from requests<3.0.0,>=2.28.1->unipressed) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from requests<3.0.0,>=2.28.1->unipressed) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from requests<3.0.0,>=2.28.1->unipressed) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from requests<3.0.0,>=2.28.1->unipressed) (2024.7.4)\n",
      "Downloading unipressed-1.4.0-py3-none-any.whl (35 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: tzdata, numpy, unipressed, pandas\n",
      "Successfully installed numpy-2.1.2 pandas-2.2.3 tzdata-2024.2 unipressed-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install unipressed pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ac536-a6d3-422e-b1de-b495827b39ad",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e23d49-421d-4d60-b947-6751a4a5369c",
   "metadata": {},
   "source": [
    "## Example 1: Get PDB files from a list of Uniprot IDs\n",
    "\n",
    "This example is based on combining Unipressed use via my MyBinder with [Biostars reply by Mensur Dlakic](https://www.biostars.org/p/9602308/#9602314).  \n",
    "One of the entries in [the original Biostars post](https://www.biostars.org/p/9602308/#9602308), Q8N183, is not solved experimentally at this time, and so the current query of Uniprot doesn't link to a PDB file. I added some code to collect such entries and get the corresponding AlphaFold models that are currently hosted & available at RCSB if you search the terms 'PDB' combined with a Uniprot ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b6fe6c-d621-4117-9fb8-a5785a331a11",
   "metadata": {},
   "source": [
    "The list with each UniProt id on a separate line should be pasted between the `'''` in the cell below. That is okay if you don't have one yet because a demo list is provided there already to get you going and you should start with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36be0192-8e0c-4c34-9f8e-a45b784b32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "l='''\n",
    "O75771\n",
    "Q8N183\n",
    "A0A0M3KKX3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e218e32-c3d1-40aa-8aaf-12b86412c771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O75771', 'Q8N183', 'A0A0M3KKX3']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell takes the item listing and makes a Python list object out of it\n",
    "id_list = l.split(\"\\n\")\n",
    "# next line uses a Python trick to remove the blank ones /empty ones that came from way I made list convenient to paste into\n",
    "id_list = [x for x in id_list if x]\n",
    "id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d90dc6-8ca7-41c1-a861-217857096137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unipressed import IdMappingClient\n",
    "import time\n",
    "request = IdMappingClient.submit(\n",
    "    source=\"UniProtKB_AC-ID\", dest=\"PDB\", ids=id_list\n",
    ")\n",
    "time.sleep(3.0)\n",
    "results_list = list(request.each_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e479966f-85b2-4312-9ded-ca911340642d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'O75771', 'to': '2KZ3'},\n",
       " {'from': 'O75771', 'to': '8FAZ'},\n",
       " {'from': 'O75771', 'to': '8GBJ'},\n",
       " {'from': 'O75771', 'to': '8OUY'},\n",
       " {'from': 'O75771', 'to': '8OUZ'},\n",
       " {'from': 'A0A0M3KKX3', 'to': '4U7N'},\n",
       " {'from': 'A0A0M3KKX3', 'to': '4U7O'},\n",
       " {'from': 'A0A0M3KKX3', 'to': '4ZKI'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332aae86-b71f-4ae5-b482-b17285fbcaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O75771</td>\n",
       "      <td>2KZ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O75771</td>\n",
       "      <td>8FAZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O75771</td>\n",
       "      <td>8GBJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O75771</td>\n",
       "      <td>8OUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O75771</td>\n",
       "      <td>8OUZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0A0M3KKX3</td>\n",
       "      <td>4U7N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0A0M3KKX3</td>\n",
       "      <td>4U7O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0A0M3KKX3</td>\n",
       "      <td>4ZKI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         from    to\n",
       "0      O75771  2KZ3\n",
       "1      O75771  8FAZ\n",
       "2      O75771  8GBJ\n",
       "3      O75771  8OUY\n",
       "4      O75771  8OUZ\n",
       "5  A0A0M3KKX3  4U7N\n",
       "6  A0A0M3KKX3  4U7O\n",
       "7  A0A0M3KKX3  4ZKI"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc13c30a-f660-4a19-bcb3-d30bf838557c",
   "metadata": {},
   "source": [
    "Identify those that failed to get experimental PDB matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731d09e8-0bba-4a8f-b334-46d7ca6a26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_with_experimental_structures = results_df['from'].unique() # Note cannot use `results_df.from.unique()` because `from` is a Python keyword used in imports\n",
    "ids_with_no_experimental_structure_exists = list(set(id_list) - set(ids_with_experimental_structures))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40fe99-17e7-4b91-b2d8-ccf3641fac07",
   "metadata": {},
   "source": [
    "Get the structures for the experimental matches:\n",
    "First we'll take advantage of Python to do this. Then we'll show the code/approach that would better match the route outlined [by Mensur Dlakic in his Biostars reply](https://www.biostars.org/p/9602308/#9602314) where the contents of a text file are piped into the retrieve command.\n",
    "\n",
    "First...   \n",
    "Staying mostly in with using in-memory Python objects and employing Jupyter conveniences. In other words, mainly not making a separate text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c5dc68-275b-4406-b586-42c696a1ae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  508k  100  508k    0     0   717k      0 --:--:-- --:--:-- --:--:--  717k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  204k  100  204k    0     0   327k      0 --:--:-- --:--:-- --:--:--  327k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  201k  100  201k    0     0   141k      0  0:00:01  0:00:01 --:--:--  141k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  451k  100  451k    0     0   678k      0 --:--:-- --:--:-- --:--:--  678k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  370k  100  370k    0     0   291k      0  0:00:01  0:00:01 --:--:--  291k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  190k  100  190k    0     0   161k      0  0:00:01  0:00:01 --:--:--  161k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  198k  100  198k    0     0   138k      0  0:00:01  0:00:01 --:--:--  138k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  194k  100  194k    0     0   118k      0  0:00:01  0:00:01 --:--:--  118k\n"
     ]
    }
   ],
   "source": [
    "pdb_ids = results_df['to'].unique() # limit to unique because no point repeating redundant entries\n",
    "for an_id in pdb_ids:\n",
    "    !curl -OL https://files.rcsb.org/download/{an_id}.cif.gz\n",
    "    !gunzip {an_id}.cif.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239295ac-81a1-435e-89a1-6ea70fc36ce8",
   "metadata": {},
   "source": [
    "Or if you want the traditional `pdb` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2571cee0-ca16-4c99-b53b-a635ff5add83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  425k  100  425k    0     0   324k      0  0:00:01  0:00:01 --:--:--  324k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  153k  100  153k    0     0   145k      0  0:00:01  0:00:01 --:--:--  145k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  155k  100  155k    0     0   264k      0 --:--:-- --:--:-- --:--:--  264k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  292k  100  292k    0     0   253k      0  0:00:01  0:00:01 --:--:--  253k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  294k  100  294k    0     0   243k      0  0:00:01  0:00:01 --:--:--  243k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  153k  100  153k    0     0   143k      0  0:00:01  0:00:01 --:--:--  143k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  157k  100  157k    0     0   137k      0  0:00:01  0:00:01 --:--:--  137k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  153k  100  153k    0     0   143k      0  0:00:01  0:00:01 --:--:--  143k\n"
     ]
    }
   ],
   "source": [
    "pdb_ids = results_df['to'].unique() # limit to unique because no point repeating redundant entries\n",
    "for an_id in pdb_ids:\n",
    "    !curl -OL https://files.rcsb.org/download/{an_id}.pdb.gz\n",
    "    !gunzip {an_id}.pdb.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8f57b2-9d11-4dcf-8131-dda5a5520d59",
   "metadata": {},
   "source": [
    "For those without experimental results, we can get the **predicted Alphafold models** in `cif` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea65f24b-27f2-4025-a04a-43f74fcd1c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  168k    0  168k    0     0   594k      0 --:--:-- --:--:-- --:--:--  596k\n"
     ]
    }
   ],
   "source": [
    "for uni_id in ids_with_no_experimental_structure_exists:\n",
    "    !curl -OL  https://alphafold.ebi.ac.uk/files/AF-{uni_id}-F1-model_v4.cif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb2c3c-88b9-47c2-a5e9-dbb92bb2f0c1",
   "metadata": {},
   "source": [
    "Or the **predicted Alphafold models** in `PDB` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fb0712-003e-40ae-9f96-617fa4f36dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  116k  100  116k    0     0   526k      0 --:--:-- --:--:-- --:--:--  527k\n"
     ]
    }
   ],
   "source": [
    "for uni_id in ids_with_no_experimental_structure_exists:\n",
    "    !curl -OL  https://alphafold.ebi.ac.uk/files/AF-{uni_id}-F1-model_v4.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ca3bc-c24b-4c00-b6ea-df35ac60315d",
   "metadata": {},
   "source": [
    "Keep in mind: **THOSE ARE ONLY PREDICTIONS.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c68240-afb2-4757-a445-cf6b00b446f2",
   "metadata": {},
   "source": [
    "Second...  \n",
    "To do it so it better matches the [Biostars reply by Mensur Dlakic](https://www.biostars.org/p/9602308/#9602314), where piping the file of the PDB ids to be retrieved to the retieval command. Note though HERE IT IS DONE WITHOUT FTP SINCE BLOCKED IN MYBINDER SESSIONS.  \n",
    "To do that, try the next two cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce18305-7b25-40d7-a511-006493b61faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_ids = results_df['to'].unique() # limit to unique because no point repeating redundant entries\n",
    "# save those ids in the Python list to a file `pdb_ids.txt` to better match what Mensur Dlakic's approach\n",
    "with open(\"pdb_ids.txt\", 'w') as f:\n",
    "    f.write(\"\\n\".join(pdb_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c31a8-6b33-4b57-95a6-852f3a9ccb3c",
   "metadata": {},
   "source": [
    "Note there should now be a file `pdb_ids.txt` in this session if you look in the file navigator pane to the left. If you already had a list of your own PDB entry ids with one on each line and no header, you could replace the content of `pdb_ids.txt` in this session with yours before running the next cell.\n",
    "\n",
    "Running next cell will actually do the downloading after we have se things up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21880da1-e984-401d-b237-116c97743061",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat pdb_ids.txt | xargs -i wget -q -o /dev/null https://files.rcsb.org/download/\"{}\".pdb # based on https://www.rcsb.org/docs/programmatic-access/file-download-services#file-access-urls-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0704681-038e-4b85-ac67-b78fa88034ef",
   "metadata": {},
   "source": [
    "Now feel free to edit the code here to and re-run these steps to focus on idenitifiers related to your interests.  \n",
    "If you make anything useful, be sure to download & save this notebook to your own local machine, along with anything useful files that got donwloaded as a result of running the code.\n",
    "\n",
    "Or continue on to look at the other sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5f825-977b-4ba9-96d3-d89e4e93ebce",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "## Example 2: Get HGNC (HUGO Gene Nomenclature Committee) IDs from a list of Uniprot IDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224504cd",
   "metadata": {},
   "source": [
    "The list with each UniProt id on a separate line should be pasted in between the `'''` in the cell below. That is okay if you don't have one yet because a demo list is provided there already to get you going and you should start with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8605e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l='''\n",
    "Q5VV41\n",
    "O14933\n",
    "Q8NFH8\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc710384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q5VV41', 'O14933', 'Q8NFH8']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell takes the item listing and makes a Python list object out of it\n",
    "id_list = l.split(\"\\n\")\n",
    "# next line uses a Python trick to remove the blank ones /empty ones that came from way I made list convenient to paste into\n",
    "id_list = [x for x in id_list if x]\n",
    "id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f5bd89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unipressed import IdMappingClient\n",
    "import time\n",
    "request = IdMappingClient.submit(\n",
    "    source=\"UniProtKB_AC-ID\", dest=\"HGNC\", ids=id_list\n",
    ")\n",
    "time.sleep(3.0)\n",
    "results_list = list(request.each_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05f4497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'Q5VV41', 'to': 'HGNC:15515'},\n",
       " {'from': 'O14933', 'to': 'HGNC:12490'},\n",
       " {'from': 'Q8NFH8', 'to': 'HGNC:9963'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebde5cf-9bf3-4d4f-a927-71debe3e5d36",
   "metadata": {},
   "source": [
    "You may wish to scroll up to the example #1 above and seee some ways to extend that here.\n",
    "\n",
    "Now feel free to edit the code here to and re-run these steps to focus on idenitifiers related to your interests. \n",
    "If you make anything useful, be sure to download & save this notebook to your own local machine, along with anything useful files that got donwloaded as a result of running the code.\n",
    "\n",
    "Or continue on to look at the other sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f4af1-de13-467e-b846-fc079cfa09ba",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "#### Additional Unipressed snippets from answers I had at StackOverflow and Biostars follow:\n",
    "\n",
    "I'll eventually better detail these but for now the links to the associated StackOverflow and Biostars answers are provided for further investigation.\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17b116-8dbf-43c2-a65e-7a01edcef600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associated with https://stackoverflow.com/a/73586628/8508004\n",
    "from unipressed import IdMappingClient\n",
    "request = IdMappingClient.submit(\n",
    "    source=\"UniProtKB_AC-ID\", dest=\"PDB\", ids={\"A0A0M3KKX3\"}\n",
    ")\n",
    "time.sleep(3.0)\n",
    "results_list = list(request.each_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a3949-6e2e-4f84-af1f-dbdeeaa572a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7658c-2ea1-4d4d-95e8-6e89c0e17115",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90f0ea-d890-48a4-89e0-e932a060af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.biostars.org/p/9560315/#9560336\n",
    "from unipressed import IdMappingClient\n",
    "import time\n",
    "request = IdMappingClient.submit(\n",
    "    source=\"UniProtKB_AC-ID\", dest=\"Gene_Name\", ids={\"P10643\",\"P11717\",\"P00450\",\"Q86VB7\",\"P27169\",\"P01871\",\"P06727\",\"O00299\", \"Q9UBX5\", \"B7ZKJ8\",\"A0A0G2JPR0\",\"P09493\",\"P35443\",\"Q9Y4F1\",\"P23141\", \"Q8WWA0\", \"P04792\", \"P26447\", \"P07237\", \"P08571\", \"Q9UPN3\", \"P14151\", \"P49908\", \"P33151\", \"P26038\"}\n",
    ")\n",
    "time.sleep(5)\n",
    "results_list = list(request.each_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f8570-1d19-48f8-99bd-9dcd3e92bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f26952-37b0-436f-aced-ed2b0440ea7b",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd1497-bc92-4124-b018-f86fb62fe256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associated with https://stackoverflow.com/a/73586386/8508004\n",
    "from unipressed import IdMappingClient\n",
    "import time\n",
    "request = IdMappingClient.submit(\n",
    "    source=\"GeneCards\", dest=\"UniProtKB\", ids={\"POTEB3\", \"SYCE3\", \"CLRN2\"}\n",
    ")\n",
    "time.sleep(5.0)\n",
    "results_list = list(request.each_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e61a86-b63e-42bf-a495-a193fcf63f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa31bb62-d8f0-4b63-9d17-fe3f8f33ad9d",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9da86-a660-4ca9-a9ef-abf9cf6d14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associated with https://stackoverflow.com/a/73587249/8508004\n",
    "from unipressed import UniprotkbClient\n",
    "UniprotkbClient.fetch_one(\"P03468\")[\"uniProtKBCrossReferences\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb2638-a4df-4438-9704-421d755490e3",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3945227-46ce-4a80-97bd-f64cb25d8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associated with https://www.biostars.org/p/286919/#9537049\n",
    "from unipressed import UniprotkbClient\n",
    "for record in UniprotkbClient.search(\n",
    "    query={\n",
    "        \"or_\": [\n",
    "        {\"ec\": \"3.1.3.9\"},\n",
    "        {\"ec\": \"2.7.1.2\"},\n",
    "        ],\n",
    "        \"and_\": [\n",
    "        {\"organism_id\": \"9606\"},\n",
    "        ]\n",
    "    },\n",
    "    #fields=[\"length\", \"gene_names\"]\n",
    ").each_record():\n",
    "    display(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b77944-8e76-4fe6-a930-fa50d86ef609",
   "metadata": {},
   "source": [
    "Get that as tab-separated values, `.tsv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5365d8f-496c-4919-ae21-0c84522b27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associated with https://www.biostars.org/p/286919/#9537049\n",
    "from unipressed import UniprotkbClient\n",
    "for record in UniprotkbClient.search(\n",
    "    query={\n",
    "        \"or_\": [\n",
    "        {\"ec\": \"3.1.3.9\"},\n",
    "        {\"ec\": \"2.7.1.2\"},\n",
    "        ],\n",
    "        \"and_\": [\n",
    "        {\"organism_id\": \"9606\"},\n",
    "        ]\n",
    "    },\n",
    "    format=\"tsv\",\n",
    "    fields=[\"accession\",\"gene_names\", \"length\"]\n",
    ").each_record():\n",
    "    display(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc6ddb-3aee-4f60-9893-ce663ed83d5b",
   "metadata": {},
   "source": [
    "Saving records as `.tsv` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccb2c80-3db6-44f7-ace0-3f585d1eea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://gist.github.com/fomightez/54e3b38c9ac516e6687924349527873d\n",
    "from unipressed import UniprotkbClient\n",
    "import shutil\n",
    "for i,record in enumerate(UniprotkbClient.search(\n",
    "    query={\n",
    "        \"or_\": [\n",
    "        {\"ec\": \"3.1.3.9\"},\n",
    "        {\"ec\": \"2.7.1.2\"},\n",
    "        ],\n",
    "        \"and_\": [\n",
    "        {\"organism_id\": \"9606\"},\n",
    "        ]\n",
    "    },\n",
    "    format=\"tsv\",\n",
    "    fields=[\"accession\",\"gene_names\", \"length\"]\n",
    ").each_page()):\n",
    "    with open(f\"{i+1}.tsv\", \"w\") as dest:\n",
    "        shutil.copyfileobj(record, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b879e1-54f1-4cbc-822f-391a7c45eb1b",
   "metadata": {},
   "source": [
    "You can filter those isoforms to get the 4 seen in the direct access by filtering out any where there's a dash in in the name (see [here](https://www.biostars.org/p/286919/#9537049) for what that my about), like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4585d15-5fca-4040-adb9-6af060e54a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associated with https://www.biostars.org/p/286919/#9537049\n",
    "from unipressed import UniprotkbClient\n",
    "\n",
    "collected=[]\n",
    "for record in UniprotkbClient.search(\n",
    "    query={\n",
    "        \"or_\": [\n",
    "        {\"ec\": \"3.1.3.9\"},\n",
    "        {\"ec\": \"2.7.1.2\"},\n",
    "        ],\n",
    "        \"and_\": [\n",
    "        {\"organism_id\": \"9606\"},\n",
    "        ]\n",
    "    },\n",
    "    fields=[\"length\", \"gene_names\"]\n",
    ").each_record():\n",
    "    collected.append(record)\n",
    "collected = [x for x in collected if \"-\" not in x[\"primaryAccession\"]]\n",
    "collected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2542312-cf24-4202-bc12-f4c1d3b745c8",
   "metadata": {},
   "source": [
    "XML Format Example:\n",
    "\n",
    "The original post in particular asked about downloading the results in XML format. And Unipressed has that built in already. Here some accessing & printing of data stored in the XML record object is done to show something human readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2a872-6ae2-46ce-b028-2213fcca37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associated with https://www.biostars.org/p/286919/#9537049 , see also https://gist.github.com/fomightez/9d6a04385d143bf7c1de34cefffc0101\n",
    "from unipressed import UniprotkbClient\n",
    "for record in UniprotkbClient.search(\n",
    "    query={\n",
    "        \"or_\": [\n",
    "        {\"ec\": \"3.1.3.9\"},\n",
    "        {\"ec\": \"2.7.1.2\"},\n",
    "        ],\n",
    "        \"and_\": [\n",
    "        {\"organism_id\": \"9606\"},\n",
    "        ]\n",
    "    },\n",
    "    format=\"xml\",\n",
    ").each_record():\n",
    "    #Show XML object as string by uncommenting out the next two lines & deleting everything after those lines\n",
    "    #from xml.etree import ElementTree # from https://stackoverflow.com/a/48671499/8508004\n",
    "    #print(ElementTree.tostring(record, encoding='unicode'))\n",
    "    #Below based on [Processing XML in Python — ElementTree:A Beginner’s Guide](https://towardsdatascience.com/processing-xml-in-python-elementtree-c8992941efd2)\n",
    "    # slice `[28:]` added to remove `{http://uniprot.org/uniprot}` from the front of tags\n",
    "    #[print(elem.tag[28:]) for elem in record.iter()]\n",
    "    #[print(child.tag, child.attrib) for child in record]\n",
    "    [print(elem.tag[28:], elem.attrib, elem.text) for elem in record.iter('{http://uniprot.org/uniprot}fullName')]\n",
    "    [print(elem.tag[28:], elem.attrib, elem.text) for elem in record.iter('{http://uniprot.org/uniprot}ecNumber')]\n",
    "    [print(elem.tag[28:], elem.attrib) for elem in record.iter('{http://uniprot.org/uniprot}proteinExistence')]\n",
    "    print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c05bed-80c0-49ef-bc9e-a3d1d1987aee",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "Enjoy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
